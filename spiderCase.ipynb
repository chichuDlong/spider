{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_1：爬取某一网站首页数据(mathType for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "if __name__ == \"__main__\":\n",
    "    # step 1: get url\n",
    "    url = 'https://www.mathtype.cn'\n",
    "    # step 2: make requests, requests.get()returns a response object\n",
    "    reponse = requests.get(url=url)\n",
    "    # step 3: get response data, text returns the data in the  formation of string\n",
    "    page_text=reponse.text\n",
    "    # print(page_text)\n",
    "    # step 4: data analysis and data save\n",
    "    with open('./web.html','w',encoding='utf-8') as fp:\n",
    "        fp.write(page_text)\n",
    "    print('over!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_2：爬取指定词条搜索结果（网页采集器——binying for example）\n",
    "处理携带参数的url，将各参数封装到dict中  \n",
    "- UA: User-Agent(请求载体的身份标识)\n",
    "- 进行UA(User-Agent)伪装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息.html save correctly!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://cn.bing.com/search?'\n",
    "    header = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    # word = input('input the infomation you need to search: ')\n",
    "    word = '信息'\n",
    "    param = {\n",
    "        'q':word\n",
    "    }\n",
    "    response = requests.get(url=url,params=param,headers=header)\n",
    "    page_text = response.text\n",
    "    # print(page_text)\n",
    "    fileName = word + '.html'\n",
    "    with open(fileName,'w',encoding='utf-8') as fp:\n",
    "        fp.write(page_text)\n",
    "    print(fileName,'save correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_3：实现百度翻译\n",
    "- 页面通过ajax刷新局部数据，网址不变，仅数据刷新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the words you need to translate:\n",
      " go\n",
      "the results:\n",
      " vi. 走; 离开; 去做; 进行 vt. 变得; 发出…声音; 成为; 处于…状态 n. 轮到的顺\n",
      "Data has been saved\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "if __name__ == \"__main__\":\n",
    "    post_url = 'https://fanyi.baidu.com/sug'\n",
    "    header = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    word = 'go'\n",
    "    data = {\n",
    "        'kw':word\n",
    "    }\n",
    "    response = requests.post(url=post_url,data=data,headers=header)\n",
    "    dic_obj = response.json()\n",
    "    # for item in dic_obj['data']:\n",
    "    print('the words you need to translate:\\n',dic_obj['data'][0]['k'])\n",
    "    print('the results:\\n',dic_obj['data'][0]['v'])\n",
    "    fileName = word + '.json'\n",
    "    fp = open(fileName,'w',encoding='utf-8')\n",
    "    json.dump(dic_obj,fp=fp,ensure_ascii=False)\n",
    "    # print(dic_obj)\n",
    "    print('Data has been saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_4：电影分类详情数据\n",
    "- 请求携带参数，将参数封装到参数字典中\n",
    "- 得到的数据为列表，列表中有各个电影信息组成的字典\n",
    "- 通过提取每一个电影中想要的信息，然后将其转换为DataFrame格式输出到Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://movie.douban.com/j/chart/top_list'\n",
    "    header = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    param = {\n",
    "        'type':'5',\n",
    "        'interval_id':'100:90',\n",
    "        'action':'',\n",
    "        'start':'0',# 可以通过参数变化爬取给定页面的信息\n",
    "        'limit':'20',# \n",
    "    }\n",
    "    response = requests.get(url=url,params=param,headers=header)\n",
    "    list_data = response.json()\n",
    "    # for item in list_data:\n",
    "    #     print('电影名字：',item['title'])\n",
    "    data=[]\n",
    "    find=False\n",
    "    for item in list_data:\n",
    "        a={'rank':item['rank'],'title':item['title'],'release_date':item['release_date'],'score':item['score']}\n",
    "        data.append(a)\n",
    "    # print(data)\n",
    "    df = pd.DataFrame(list_data)\n",
    "    df2 = pd.DataFrame(data)\n",
    "    # print(df)\n",
    "\n",
    "    # 将信息写入Excel，index——是否保留索引，header——是否保留表头（列名）\n",
    "    df.to_excel('douban.xlsx',encoding='utf-8',index=False)\n",
    "    df2.to_excel('dataAnalysis.xlsx',encoding='utf-8',index=False)\n",
    "    # print(list_data)\n",
    "    fp = open('douban.json','w',encoding='utf-8')\n",
    "    json.dump(list_data,fp=fp,ensure_ascii=False)\n",
    "    print(\"Data has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_5：肯德基餐厅信息查询(官网：http://www.kfc.com.cn/kfccda/index.aspx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mission_6：药品相关企业详情信息(http://scxk.nmpa.gov.cn:81/xk/)\n",
    "- 动态加载的数据无法直接通过地址请求得到想要的结果  \n",
    "- 首页中对应的企业信息是通过ajax请求得到的  \n",
    "- 某一企业的详情页是通过前面企业信息请求得到的id值得到"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "501834c540f8b330c04c1d43ec1666643355d13f80c9caf7e1080236b3fb263f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
